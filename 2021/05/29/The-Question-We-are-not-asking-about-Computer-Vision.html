<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>The Question We are not asking about Computer Vision. | Aamir</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="The Question We are not asking about Computer Vision." />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Cogito, ergo sum, ( “I think, therefore I am)" />
<meta property="og:description" content="Cogito, ergo sum, ( “I think, therefore I am)" />
<link rel="canonical" href="https://aamirai.github.io/square/2021/05/29/The-Question-We-are-not-asking-about-Computer-Vision.html" />
<meta property="og:url" content="https://aamirai.github.io/square/2021/05/29/The-Question-We-are-not-asking-about-Computer-Vision.html" />
<meta property="og:site_name" content="Aamir" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-29T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-05-29T00:00:00-05:00","url":"https://aamirai.github.io/square/2021/05/29/The-Question-We-are-not-asking-about-Computer-Vision.html","@type":"BlogPosting","headline":"The Question We are not asking about Computer Vision.","dateModified":"2021-05-29T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://aamirai.github.io/square/2021/05/29/The-Question-We-are-not-asking-about-Computer-Vision.html"},"description":"Cogito, ergo sum, ( “I think, therefore I am)","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/square/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://aamirai.github.io/square/feed.xml" title="Aamir" /><link rel="shortcut icon" type="image/x-icon" href="/square/images/bash-icon.ico">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/square/">Aamir</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/square/about/">About Me</a><a class="page-link" href="/square/search/">Search</a><a class="page-link" href="/square/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">The Question We are not asking about Computer Vision.</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-05-29T00:00:00-05:00" itemprop="datePublished">
        May 29, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/aamirai/square/tree/master/_notebooks/2021-05-29-The Question We are not asking about Computer Vision..ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/square/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/aamirai/square/master?filepath=_notebooks%2F2021-05-29-The+Question+We+are+not+asking+about+Computer+Vision..ipynb" target="_blank">
        <img class="notebook-badge-image" src="/square/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/aamirai/square/blob/master/_notebooks/2021-05-29-The Question We are not asking about Computer Vision..ipynb" target="_blank">
        <img class="notebook-badge-image" src="/square/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-05-29-The Question We are not asking about Computer Vision..ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In Computer Vision we are at very good stage to recognize object we created models etc algorithms to image classifcation
we didn't not only stop there we went ahead we also achieved succes in object localization which means given in an image we 
can now identify where the object is with highest accuracy to identifying dozens of other classes. But as of many challenging 
problem in computer which are out there. We must pause for a minute and ask question what all can we do with state of the art and what more can we contribute to it? But we must think, although we have achieved so much good in computer vision what all we can do with it. Given a problem with in computer vision lets say given a store, the store manages wants to evaluate the broad
varieties of customer walk in so they can target there customer with wide range of products.
I know what you are thinking install a camera at the gate of start collecting your data on wide range of classed young, adult, mature,old or by the age group so that its more appealing to business problem.
But, think for a minute there is so much you have to do apart from the creating model.
for ex:</p>
<blockquote><p>You have to evaluate the customer only on entering the store not to counts them twice.<br />
Your models should be robust such that it count the number of customer for each class and create database of it.<br />
You also have to take care of burgalary, shoplyfting some mischivieos activity etc</p>
</blockquote>
<p>The point that I want to convey is, there is more than AI job you have to do here than simply doing a computer vision task i.e lot of coding and algorithms to test. But it certainly sound obscure to me. When I learned machine learning a diagram was in the slide which is resting in my mind since then, which is:<img src="/square/images/copied_from_nb/vqa/ml.jpg" alt="" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here is one such thing I came across with, Visual Question Answering or VQA which started in 2010 if I am not wrong, www.vizwiz.org is the site which hosts the challenge every year. The concept is similar to image captioning but I am not going that road to tell the differences. Here the task is very specefic and challenging the job is to make world a better place for visually impaired people. That is given a task it should match clearly to the real world with context.</p>
<blockquote><p>YES! Context</p>
</blockquote>
<p><img src="/square/images/copied_from_nb/vqa/model.png" alt="" />
If you ask any machine learnig enthusiast to develop an application for visually impaired person or blind person the de facto answer I got is "Use computer vision and let the model speak out what is in front of" this sounds reasonable. But the thing we are missing what challenges where a blind person come across what are the struggles they face everyday, does this model is going to solve the problem. The paper I discussing is from vizwiz.org <a href="https://www.cs.cmu.edu/~jbigham/pubs/pdfs/2010/vizwiz.pdf">https://www.cs.cmu.edu/~jbigham/pubs/pdfs/2010/vizwiz.pdf</a> which is <strong>VizWiz: Nearly Real-time Answers to Visual Questions.</strong> But before that look at the given picture below <img src="/square/images/copied_from_nb/vqa/vqa.png" alt="" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The VQA is the intersection of CV, ML, NLP and Reasoning. Don't get intimidated by the concepts you have to learn. It sounds fun you are trying to solve it.
<strong>Now, VQA</strong>
Basically it first devloped on mobile devices 10 years back the ascnesion of smartphone has just started. With iphone 3GS.
It was develop to ask question by the user expecting a response what's in front of it. The best part of the paper I liked about it the paper talked about generalized model which will be totally vague. The author used the term <strong>SKILL</strong> they targeted on a specific skill to monitor the problem.For example:  a visually challengedd person is buying grocery.<br />
This sounds reasonable and doable and seems like we could solve the problem. <br />
Let me stop you there, you are still not thinking yourself what are the problems he may come across. <br />
Like,</p>
<blockquote><p>What is the product he wants to buy<br />
what is the expiration of the product <br />
If its apparel what size and color it is.<br />
what is the correct bill I am paying i.e identifying the currency.<br /></p>
</blockquote>
<p>This is the best part of the paper they tried to answer, Think how a blind person can use the camera, they found out that (11.0%) of the images taken were too dark for the question to be answered, and 17 (21.0%)
were too blurry for the question to be answered. It blows my mind how a blind person will know how to focus and what simply srufacing the camera towards it is not going to give answers. Look at the image below 
<img src="/square/images/copied_from_nb/vqa/ques.png" alt="" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/square/images/copied_from_nb/vqa/q1.png" alt="" />
The given images shows the quality of image taken by them and how it is difficult for them to get things straight from real world.
There is more to images which in this blog post is not possible. I will keep posting regarding VQA like how to solve, the architecture, how the datasets look like etc.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/square/2021/05/29/The-Question-We-are-not-asking-about-Computer-Vision.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/square/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/square/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/square/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Cogito, ergo sum, ( “I think, therefore I am)</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://twitter.com/amirmeansprince" title="amirmeansprince"><svg class="svg-icon grey"><use xlink:href="/square/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
